from strands import Agent
from strands_tools import http_request
from strands.models import OllamaModel
import os

# Add this before creating the agent
ollama_model = OllamaModel(
    host="http://localhost:11434",
    model_id="deepseek-r1:latest"  \
)

print("Starting script...")
print("Imports successful")
# Define a weather-focused system prompt
WEATHER_SYSTEM_PROMPT = """You are a weather assistant with HTTP capabilities. You can:

1. Make HTTP requests to the National Weather Service API
2. Process and display weather forecast data
3. Provide weather information for locations in the United States

When retrieving weather information:
1. First get the coordinates or grid information using https://api.weather.gov/points/{latitude},{longitude} or https://api.weather.gov/points/{zipcode}
2. Then use the returned forecast URL to get the actual forecast

When displaying responses:
- Format weather data in a human-readable way
- Highlight important information like temperature, precipitation, and alerts
- Handle errors appropriately
- Convert technical terms to user-friendly language

Always explain the weather conditions clearly and provide context for the forecast.
"""

print("Creating agent...")

try:
    # Create an agent with HTTP capabilities
    weather_agent = Agent(
        system_prompt=WEATHER_SYSTEM_PROMPT,
        tools=[http_request],
    )
    print("Agent created successfully")
    
    print("Sending query to agent...")
    response = weather_agent("What's the weather like in Seattle?")
    
    print("Got response from agent")
    print("Response type:", type(response))
    print("Response content:", repr(response))
    print("Response (normal print):", response)
    
except Exception as e:
    print("Error occurred:", str(e))
    print("Error type:", type(e))
    import traceback
    traceback.print_exc()

print("Script finished")
# Create an agent with HTTP capabilities
#weather_agent = Agent(
    #system_prompt=WEATHER_SYSTEM_PROMPT,
    #tools=[http_request],  # Explicitly enable http_request tool
    #model=ollama_model
#)
#response = weather_agent("What's the weather like in Seattle?")
#print(response)
